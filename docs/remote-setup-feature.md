# Feature: Custom Test Orchestration System mit Remote Workers

**Status:** Konzept / Planung
**Priorit√§t:** Hoch
**Aufwand:** ~42 Stunden (Initial Development) + 2-4h/Monat Wartung
**Kosten:** ‚Ç¨0/Monat (nutzt vorhandenes HostEurope Hosting)

---

## Executive Summary

Ein custom-entwickeltes, zentrales Test-Orchestrierungs-System, das es erm√∂glicht:
- Beliebig viele Test-Rechner (Laptops, Desktops, VMs) als Worker zu registrieren
- Tests automatisch und intelligent auf verf√ºgbare Worker zu verteilen
- Via Web-Dashboard Tests zu starten, zu √ºberwachen und Ergebnisse zu analysieren
- **100+ parallele Tests** gleichzeitig auszuf√ºhren (abh√§ngig von verf√ºgbaren Workern)

Das System nutzt das bereits vorhandene HostEurope Webhosting (PHP + MySQL) als Coordinator und Worker-Agents (Node.js) auf allen Test-Rechnern.

---

## Skalierbarkeits-Berechnung

### Beispiel-Szenarien

| Szenario | Anzahl Worker | Tests/Worker parallel | **Gesamt parallele Tests** | Hardware |
|----------|---------------|----------------------|---------------------------|----------|
| **Klein** | 3 Worker | 4 parallel | **12 gleichzeitig** | 3√ó Laptops |
| **Mittel** | 10 Worker | 8 parallel | **80 gleichzeitig** | 5√ó Laptops + 5√ó Desktops |
| **Gro√ü** | 20 Worker | 10 parallel | **200 gleichzeitig** | 10√ó Desktops + 10√ó VMs |
| **Enterprise** | 50 Worker | 20 parallel | **1.000 gleichzeitig** | 50√ó Cloud VMs (spot instances) |

### Konkrete Rechnung f√ºr Globetrotter Setup

Angenommen:
- **5 Team-Laptops** (w√§hrend Arbeit verf√ºgbar)
- **3 Team-Desktops** (24/7 verf√ºgbar)
- **2 alte Rechner** (dedicated Test-Maschinen)
- **5 AWS EC2 Spot Instances** (bei Bedarf, ~$0.02/h)

```
Tags√ºber (Mo-Fr 9-17 Uhr):
= 5 Laptops √ó 6 parallel + 3 Desktops √ó 10 parallel + 2 dedicated √ó 15 parallel
= 30 + 30 + 30
= 90 parallele Tests gleichzeitig

Nachts (automatisiert):
= 3 Desktops √ó 10 parallel + 2 dedicated √ó 15 parallel + 5 EC2 √ó 20 parallel
= 30 + 30 + 100
= 160 parallele Tests gleichzeitig

Bei Bedarf (Peak-Load-Tests):
= Alle oben + 20 zus√§tzliche EC2 Spot Instances √ó 20 parallel
= 160 + 400
= 560 parallele Tests gleichzeitig
```

**Kosten f√ºr Peak-Szenario:**
- 25√ó AWS EC2 t3.xlarge Spot Instances f√ºr 2 Stunden = ~25 √ó $0.02 √ó 2h = **$1 pro Peak-Test-Run**

---

## Architektur-√úbersicht

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HOSTEUROPE WEBHOSTING                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                     WEB FRONTEND                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Dashboard  ‚îÇ  ‚îÇ Test-Runs  ‚îÇ  ‚îÇ Analytics  ‚îÇ             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ index.php  ‚îÇ  ‚îÇ runs.php   ‚îÇ  ‚îÇ stats.php  ‚îÇ             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Workers    ‚îÇ  ‚îÇ Logs       ‚îÇ  ‚îÇ Settings   ‚îÇ             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ workers.php‚îÇ  ‚îÇ logs.php   ‚îÇ  ‚îÇ config.php ‚îÇ             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                      REST API LAYER                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Worker Management API                                   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/workers/register                        ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/workers/{id}                            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  PUT    /api/v1/workers/{id}/heartbeat                  ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  DELETE /api/v1/workers/{id}                            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/workers (list all)                      ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Task Management API                                     ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/tasks/next (worker polls for task)      ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/tasks/{id}/claim                        ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/tasks/{id}/start                        ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/tasks/{id}/complete                     ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/tasks/{id}/fail                         ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/tasks/{id}/heartbeat                    ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Test Run Management API                                 ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/test-runs/create                        ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/test-runs/{id}                          ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/test-runs/{id}/progress                 ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/test-runs/{id}/cancel                   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/test-runs (list + filter)               ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Results & Reporting API                                 ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  POST   /api/v1/results/submit                          ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/results/{test_run_id}                   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/results/{test_run_id}/download          ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/metrics/performance                     ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  GET    /api/v1/metrics/trends                          ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    BUSINESS LOGIC LAYER                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Scheduler   ‚îÇ  ‚îÇ LoadBalancer ‚îÇ  ‚îÇ HealthCheck  ‚îÇ       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (Cron)      ‚îÇ  ‚îÇ (Task‚ÜíWorker)‚îÇ  ‚îÇ (Workers)    ‚îÇ       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Aggregator   ‚îÇ  ‚îÇ Notifier     ‚îÇ  ‚îÇ Cleaner      ‚îÇ       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Merge Rslts)‚îÇ  ‚îÇ (Alerts)     ‚îÇ  ‚îÇ (Old Data)   ‚îÇ       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                      DATABASE LAYER                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  MySQL 8.0+ (InnoDB)                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ workers  ‚îÇ ‚îÇtest_runs ‚îÇ ‚îÇ  tasks   ‚îÇ ‚îÇ results  ‚îÇ        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  logs    ‚îÇ ‚îÇ  metrics ‚îÇ ‚îÇ  alerts  ‚îÇ ‚îÇ  config  ‚îÇ        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    FILE STORAGE LAYER                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - HTML Reports: /reports/{test_run_id}/{task_id}/           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Screenshots:  /screenshots/{test_run_id}/{task_id}/       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Videos:       /videos/{test_run_id}/{task_id}/            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Traces:       /traces/{test_run_id}/{task_id}/            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñ≤ HTTPS REST API
                              ‚îÇ (Polling every 10-60s)
                              ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                       ‚îÇ                               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker 1   ‚îÇ      ‚îÇ   Worker 2      ‚îÇ    ...    ‚îÇ   Worker N      ‚îÇ
‚îÇ  (Laptop)   ‚îÇ      ‚îÇ   (Desktop)     ‚îÇ           ‚îÇ   (EC2 Spot)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Node.js     ‚îÇ      ‚îÇ Node.js Agent   ‚îÇ           ‚îÇ Node.js Agent   ‚îÇ
‚îÇ Agent       ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ                 ‚îÇ
‚îÇ             ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ                 ‚îÇ
‚îÇ Capabilities‚îÇ      ‚îÇ Capabilities:   ‚îÇ           ‚îÇ Capabilities:   ‚îÇ
‚îÇ - 4 parallel‚îÇ      ‚îÇ - 10 parallel   ‚îÇ           ‚îÇ - 20 parallel   ‚îÇ
‚îÇ - Chromium  ‚îÇ      ‚îÇ - All browsers  ‚îÇ           ‚îÇ - All browsers  ‚îÇ
‚îÇ - 8GB RAM   ‚îÇ      ‚îÇ - 32GB RAM      ‚îÇ           ‚îÇ - 64GB RAM      ‚îÇ
‚îÇ             ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ                 ‚îÇ
‚îÇ Status:     ‚îÇ      ‚îÇ Status:         ‚îÇ           ‚îÇ Status:         ‚îÇ
‚îÇ BUSY (3/4)  ‚îÇ      ‚îÇ IDLE (0/10)     ‚îÇ           ‚îÇ BUSY (18/20)    ‚îÇ
‚îÇ             ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ                 ‚îÇ
‚îÇ Current:    ‚îÇ      ‚îÇ Waiting for     ‚îÇ           ‚îÇ Running:        ‚îÇ
‚îÇ ‚îú‚îÄ Task 42  ‚îÇ      ‚îÇ next task...    ‚îÇ           ‚îÇ ‚îú‚îÄ Task 78-95   ‚îÇ
‚îÇ ‚îú‚îÄ Task 43  ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ ‚îî‚îÄ 18 tasks     ‚îÇ
‚îÇ ‚îî‚îÄ Task 44  ‚îÇ      ‚îÇ                 ‚îÇ           ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Komponenten-√úbersicht

### 1. HostEurope Coordinator (PHP + MySQL)

**Verantwortlichkeiten:**
- Worker-Registration & Health-Monitoring
- Task-Scheduling & Load-Balancing
- Test-Run Management
- Ergebnis-Aggregation
- Web-Dashboard f√ºr Benutzer
- REST API f√ºr Workers

**Technologie-Stack:**
- PHP 8.0+ (Backend)
- MySQL 8.0+ (Datenbank)
- Bootstrap 5 / Tailwind CSS (Frontend)
- Chart.js (Visualisierungen)
- Apache/Nginx (Webserver)

### 2. Worker Agent (Node.js)

**Verantwortlichkeiten:**
- Registrierung beim Coordinator
- Polling f√ºr neue Tasks (alle 10-60 Sekunden)
- Playwright-Tests ausf√ºhren
- Ergebnisse zur√ºckmelden
- System-Metriken sammeln (CPU, RAM)
- Heartbeat senden

**Technologie-Stack:**
- Node.js 20+
- Axios (HTTP Client)
- Playwright (Test-Execution)
- OS-Modul (System-Metriken)

### 3. Datenbank-Schema

Siehe ausf√ºhrliches Schema in `schema-detailed.sql` (unten)

**Haupttabellen:**
- `workers` - Registrierte Test-Rechner
- `test_runs` - Test-Sessions
- `tasks` - Einzelne Test-Shards
- `test_results` - Detaillierte Ergebnisse
- `worker_logs` - Heartbeat & Event-Log
- `performance_metrics` - Trend-Daten
- `alerts` - Alert-Definitionen
- `config` - System-Konfiguration

---

## Umsetzungsschritte (Detailliert)

| Phase | Schritt | Beschreibung | Technologie | Aufwand | Dateien |
|-------|---------|--------------|-------------|---------|---------|
| **Phase 1: Foundation** | 1.1 Datenbank-Schema | MySQL-Tabellen, Views, Stored Procedures, Triggers | MySQL | 2h | `schema-detailed.sql` |
| | 1.2 API Config | Datenbank-Verbindung, Auth-Helper | PHP | 1h | `api/config.php` |
| | 1.3 Load Balancer | Task-Verteilungs-Logik | PHP | 4h | `api/lib/LoadBalancer.php` |
| **Phase 2: API** | 2.1 Worker Management | Register, Heartbeat, Status | PHP | 4h | `api/v1/workers/*.php` |
| | 2.2 Task Management | Next Task, Claim, Complete, Fail | PHP | 4h | `api/v1/tasks/*.php` |
| | 2.3 Test Run Management | Create, List, Progress, Cancel | PHP | 3h | `api/v1/test-runs/*.php` |
| | 2.4 Results API | Submit, Download, Metrics | PHP | 3h | `api/v1/results/*.php` |
| **Phase 3: Worker Agent** | 3.1 Agent Core | Registration, Polling, Heartbeat | Node.js | 4h | `agent/worker.js` |
| | 3.2 Task Execution | Playwright-Integration | Node.js | 3h | `agent/executor.js` |
| | 3.3 Results Upload | Ergebnisse & Artifacts hochladen | Node.js | 2h | `agent/uploader.js` |
| **Phase 4: Web UI** | 4.1 Dashboard | √úbersicht Worker & Test-Runs | PHP/HTML | 4h | `index.php` |
| | 4.2 Worker View | Worker-Details, Logs | PHP/HTML | 2h | `workers.php` |
| | 4.3 Test Run Details | Fortschritt, Ergebnisse | PHP/HTML | 3h | `runs.php` |
| | 4.4 Analytics | Performance-Trends, Charts | PHP/Chart.js | 3h | `stats.php` |
| **Phase 5: Automation** | 5.1 Scheduler | Cron-Jobs f√ºr wiederkehrende Tests | PHP/Cron | 2h | `scheduler.php` |
| | 5.2 Alerting | Slack/Email-Benachrichtigungen | PHP | 2h | `notifier.php` |
| | 5.3 Cleanup | Alte Daten l√∂schen | PHP/MySQL Events | 1h | In Schema |
| **Phase 6: Deployment** | 6.1 HostEurope Upload | FTP/Git Deploy | - | 1h | - |
| | 6.2 Worker Installation | Agent auf allen Rechnern | - | 2h | `install.sh` / `.bat` |
| | 6.3 Testing & Bugfixes | End-to-End Tests | - | 4h | - |
| **Gesamt** | | | | **~48h** | |

---

## Datenbank-Schema (Komplett)

```sql
-- schema-detailed.sql
CREATE DATABASE IF NOT EXISTS playwright_orchestrator
CHARACTER SET utf8mb4
COLLATE utf8mb4_unicode_ci;

USE playwright_orchestrator;

-- ============================================================================
-- TABLE: workers
-- Speichert alle registrierten Test-Worker (Rechner)
-- ============================================================================
CREATE TABLE workers (
    id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,

    -- Identifikation
    hostname VARCHAR(255) NOT NULL UNIQUE COMMENT 'Eindeutiger Hostname/Name des Workers',
    ip_address VARCHAR(45) NULL COMMENT 'IPv4 oder IPv6 Adresse',
    api_key CHAR(64) NOT NULL UNIQUE COMMENT 'SHA256 API-Key f√ºr Authentifizierung',

    -- Status
    status ENUM('idle', 'busy', 'offline', 'maintenance') DEFAULT 'offline'
        COMMENT 'idle=bereit, busy=arbeitet, offline=nicht erreichbar, maintenance=deaktiviert',

    -- Capabilities (JSON)
    capabilities JSON NULL COMMENT 'Worker-F√§higkeiten: browsers, max_parallel, platform, etc.',

    -- Limits & Configuration
    max_parallel_tasks INT UNSIGNED DEFAULT 4
        COMMENT 'Maximale Anzahl paralleler Tasks',
    current_tasks_count INT UNSIGNED DEFAULT 0
        COMMENT 'Aktuelle Anzahl laufender Tasks (Cache)',

    -- Priority & Load Balancing
    priority INT DEFAULT 100 COMMENT 'Worker-Priorit√§t (h√∂her = bevorzugt)',
    weight DECIMAL(3,2) DEFAULT 1.0 COMMENT 'Gewichtung f√ºr Task-Verteilung (0.0 - 1.0)',

    -- Monitoring
    total_tasks_completed INT UNSIGNED DEFAULT 0,
    total_tasks_failed INT UNSIGNED DEFAULT 0,
    avg_task_duration_ms INT UNSIGNED NULL,

    -- Health Check
    last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    health_check_failures INT UNSIGNED DEFAULT 0,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    -- Metadata
    tags JSON NULL,
    notes TEXT NULL,

    -- Indexes
    INDEX idx_status (status),
    INDEX idx_last_seen (last_seen),
    INDEX idx_priority (priority DESC)
) ENGINE=InnoDB;

-- ============================================================================
-- TABLE: test_runs
-- Ein Test-Run repr√§sentiert eine komplette Test-Session
-- ============================================================================
CREATE TABLE test_runs (
    id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,

    -- Identifikation
    name VARCHAR(255) NOT NULL,
    description TEXT NULL,

    -- Konfiguration
    config JSON NOT NULL COMMENT 'Test-Konfiguration (Browser, URL, Timeouts, etc.)',

    -- Sharding
    total_shards INT UNSIGNED NOT NULL DEFAULT 1,
    total_tests INT UNSIGNED DEFAULT 0,

    -- Status & Progress
    status ENUM('pending', 'scheduling', 'running', 'completed', 'failed', 'cancelled')
        DEFAULT 'pending',
    progress_percentage DECIMAL(5,2) DEFAULT 0.00,

    -- Scheduling
    scheduled_for TIMESTAMP NULL,
    schedule_cron VARCHAR(100) NULL,

    -- Execution tracking
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    duration_ms BIGINT UNSIGNED NULL,

    -- Results aggregation
    total_passed INT UNSIGNED DEFAULT 0,
    total_failed INT UNSIGNED DEFAULT 0,
    total_skipped INT UNSIGNED DEFAULT 0,
    success_rate DECIMAL(5,2) DEFAULT 0.00,

    -- User tracking
    created_by VARCHAR(100) NULL,

    -- Metadata
    tags JSON NULL,
    metadata JSON NULL,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    -- Indexes
    INDEX idx_status (status),
    INDEX idx_created_at (created_at DESC),
    INDEX idx_scheduled_for (scheduled_for)
) ENGINE=InnoDB;

-- ============================================================================
-- TABLE: tasks
-- Ein Task ist ein einzelner Test-Shard der auf einem Worker ausgef√ºhrt wird
-- ============================================================================
CREATE TABLE tasks (
    id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,

    -- Relations
    test_run_id INT UNSIGNED NOT NULL,
    worker_id INT UNSIGNED NULL,

    -- Shard Information
    shard_index INT UNSIGNED NOT NULL,
    shard_total INT UNSIGNED NOT NULL,

    -- Status
    status ENUM('pending', 'assigned', 'running', 'completed', 'failed', 'timeout', 'cancelled')
        DEFAULT 'pending',

    -- Retry logic
    retry_count INT UNSIGNED DEFAULT 0,
    max_retries INT UNSIGNED DEFAULT 2,

    -- Timing
    assigned_at TIMESTAMP NULL,
    started_at TIMESTAMP NULL,
    last_heartbeat_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    duration_ms BIGINT UNSIGNED NULL,

    -- Timeout handling
    timeout_seconds INT UNSIGNED DEFAULT 3600,

    -- Priority
    priority INT DEFAULT 100,

    -- Error tracking
    error_message TEXT NULL,
    error_stack TEXT NULL,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    -- Foreign Keys
    FOREIGN KEY (test_run_id) REFERENCES test_runs(id) ON DELETE CASCADE,
    FOREIGN KEY (worker_id) REFERENCES workers(id) ON DELETE SET NULL,

    -- Indexes
    INDEX idx_test_run (test_run_id),
    INDEX idx_worker (worker_id),
    INDEX idx_status (status),
    INDEX idx_priority (priority DESC)
) ENGINE=InnoDB;

-- ============================================================================
-- TABLE: test_results
-- Detaillierte Ergebnisse eines Tasks
-- ============================================================================
CREATE TABLE test_results (
    id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,

    -- Relation
    task_id INT UNSIGNED NOT NULL UNIQUE,

    -- Test counts
    total_tests INT UNSIGNED DEFAULT 0,
    passed INT UNSIGNED DEFAULT 0,
    failed INT UNSIGNED DEFAULT 0,
    skipped INT UNSIGNED DEFAULT 0,
    flaky INT UNSIGNED DEFAULT 0,

    -- Performance metrics
    duration_ms BIGINT UNSIGNED DEFAULT 0,
    avg_test_duration_ms INT UNSIGNED NULL,
    p50_duration_ms INT UNSIGNED NULL,
    p95_duration_ms INT UNSIGNED NULL,
    p99_duration_ms INT UNSIGNED NULL,

    -- Resource usage
    peak_memory_mb INT UNSIGNED NULL,
    avg_cpu_percent DECIMAL(5,2) NULL,

    -- Files & Artifacts
    report_html_url VARCHAR(512) NULL,
    report_json_url VARCHAR(512) NULL,
    trace_url VARCHAR(512) NULL,
    video_urls JSON NULL,
    screenshot_urls JSON NULL,

    -- Logs
    stdout_log MEDIUMTEXT NULL,
    stderr_log MEDIUMTEXT NULL,

    -- Custom metrics
    custom_metrics JSON NULL,

    -- Failed tests detail
    failed_tests JSON NULL,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Foreign Key
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE,

    -- Indexes
    INDEX idx_task (task_id),
    INDEX idx_created_at (created_at DESC)
) ENGINE=InnoDB;

-- ============================================================================
-- TABLE: worker_logs
-- Heartbeat & Event-Log f√ºr Worker
-- ============================================================================
CREATE TABLE worker_logs (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,

    -- Relation
    worker_id INT UNSIGNED NOT NULL,

    -- Event
    event_type ENUM(
        'register',
        'heartbeat',
        'task_claimed',
        'task_started',
        'task_heartbeat',
        'task_completed',
        'task_failed',
        'error',
        'shutdown'
    ) NOT NULL,

    -- Context
    task_id INT UNSIGNED NULL,

    -- Message & Data
    message TEXT NULL,
    data JSON NULL,

    -- System metrics
    cpu_percent DECIMAL(5,2) NULL,
    memory_used_mb INT UNSIGNED NULL,
    memory_total_mb INT UNSIGNED NULL,
    disk_free_gb INT UNSIGNED NULL,

    -- Timestamp
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Foreign Keys
    FOREIGN KEY (worker_id) REFERENCES workers(id) ON DELETE CASCADE,
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE SET NULL,

    -- Indexes
    INDEX idx_worker (worker_id),
    INDEX idx_created_at (created_at DESC),
    INDEX idx_event_type (event_type)
) ENGINE=InnoDB;

-- ============================================================================
-- TABLE: config
-- System-Konfiguration (Key-Value Store)
-- ============================================================================
CREATE TABLE config (
    config_key VARCHAR(100) PRIMARY KEY,
    config_value TEXT NOT NULL,
    value_type ENUM('string', 'int', 'float', 'boolean', 'json') DEFAULT 'string',
    description TEXT NULL,
    is_secret BOOLEAN DEFAULT FALSE,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    updated_by VARCHAR(100) NULL
) ENGINE=InnoDB;

-- Default config values
INSERT INTO config (config_key, config_value, value_type, description) VALUES
('worker_heartbeat_timeout_seconds', '120', 'int', 'Worker als offline markieren nach X Sekunden'),
('task_timeout_default_seconds', '3600', 'int', 'Standard-Timeout f√ºr Tasks (1 Stunde)'),
('task_max_retries', '2', 'int', 'Maximale Anzahl automatischer Task-Wiederholungen'),
('scheduler_enabled', 'true', 'boolean', 'Automatisches Scheduling aktiviert'),
('load_balancer_strategy', 'least_loaded', 'string', 'Strategie: least_loaded, round_robin, priority, weighted'),
('report_retention_days', '90', 'int', 'Aufbewahrungsdauer f√ºr Reports in Tagen'),
('log_retention_days', '30', 'int', 'Aufbewahrungsdauer f√ºr Logs'),
('max_parallel_test_runs', '10', 'int', 'Maximale Anzahl gleichzeitiger Test-Runs'),
('slack_webhook_url', '', 'string', 'Slack Webhook f√ºr Notifications'),
('smtp_server', '', 'string', 'SMTP Server f√ºr Email-Alerts');

-- ============================================================================
-- VIEWS
-- ============================================================================

-- View: Worker mit aktuellen Stats
CREATE VIEW v_workers_current AS
SELECT
    w.*,
    TIMESTAMPDIFF(SECOND, w.last_seen, NOW()) as seconds_since_seen,
    CASE
        WHEN TIMESTAMPDIFF(SECOND, w.last_seen, NOW()) > 120 THEN 'offline'
        ELSE w.status
    END as effective_status,
    (SELECT COUNT(*) FROM tasks t WHERE t.worker_id = w.id AND t.status IN ('assigned', 'running')) as current_tasks,
    w.max_parallel_tasks - (SELECT COUNT(*) FROM tasks t WHERE t.worker_id = w.id AND t.status IN ('assigned', 'running')) as available_slots
FROM workers w;

-- View: Test-Run Progress
CREATE VIEW v_test_runs_progress AS
SELECT
    tr.*,
    COUNT(t.id) as total_tasks,
    SUM(CASE WHEN t.status = 'completed' THEN 1 ELSE 0 END) as completed_tasks,
    SUM(CASE WHEN t.status = 'failed' THEN 1 ELSE 0 END) as failed_tasks,
    SUM(CASE WHEN t.status = 'running' THEN 1 ELSE 0 END) as running_tasks,
    ROUND((SUM(CASE WHEN t.status IN ('completed', 'failed') THEN 1 ELSE 0 END) / COUNT(t.id)) * 100, 2) as progress_pct
FROM test_runs tr
LEFT JOIN tasks t ON tr.id = t.test_run_id
GROUP BY tr.id;

-- ============================================================================
-- STORED PROCEDURES
-- ============================================================================

DELIMITER //

CREATE PROCEDURE sp_claim_next_task(
    IN p_worker_id INT UNSIGNED,
    OUT p_task_id INT UNSIGNED
)
BEGIN
    DECLARE v_max_parallel INT;
    DECLARE v_current_tasks INT;

    SELECT max_parallel_tasks INTO v_max_parallel
    FROM workers WHERE id = p_worker_id;

    SELECT COUNT(*) INTO v_current_tasks
    FROM tasks
    WHERE worker_id = p_worker_id AND status IN ('assigned', 'running');

    IF v_current_tasks >= v_max_parallel THEN
        SET p_task_id = NULL;
    ELSE
        SELECT t.id INTO p_task_id
        FROM tasks t
        JOIN test_runs tr ON t.test_run_id = tr.id
        WHERE t.status = 'pending'
          AND tr.status = 'running'
        ORDER BY t.priority DESC, t.id ASC
        LIMIT 1
        FOR UPDATE;

        IF p_task_id IS NOT NULL THEN
            UPDATE tasks
            SET status = 'assigned',
                worker_id = p_worker_id,
                assigned_at = NOW()
            WHERE id = p_task_id;

            UPDATE workers
            SET current_tasks_count = current_tasks_count + 1,
                status = 'busy'
            WHERE id = p_worker_id;
        END IF;
    END IF;
END//

CREATE PROCEDURE sp_check_worker_health()
BEGIN
    DECLARE v_timeout INT;

    SELECT config_value INTO v_timeout
    FROM config WHERE config_key = 'worker_heartbeat_timeout_seconds';

    UPDATE workers
    SET status = 'offline',
        health_check_failures = health_check_failures + 1
    WHERE TIMESTAMPDIFF(SECOND, last_seen, NOW()) > v_timeout
      AND status != 'offline'
      AND status != 'maintenance';
END//

DELIMITER ;

-- ============================================================================
-- MYSQL EVENTS (Cron-Jobs)
-- ============================================================================

SET GLOBAL event_scheduler = ON;

CREATE EVENT evt_worker_health_check
ON SCHEDULE EVERY 2 MINUTE
DO CALL sp_check_worker_health();

CREATE EVENT evt_cleanup_old_logs
ON SCHEDULE EVERY 1 DAY
STARTS (TIMESTAMP(CURRENT_DATE) + INTERVAL 3 HOUR)
DO
DELETE FROM worker_logs
WHERE created_at < DATE_SUB(NOW(), INTERVAL (SELECT config_value FROM config WHERE config_key = 'log_retention_days') DAY);
```

---

## Load Balancing Strategien

Das System unterst√ºtzt verschiedene Strategien zur Task-Verteilung:

### 1. Least Loaded (Standard)
W√§hlt den Worker mit den meisten freien Slots:
```
Worker A: 2/10 Tasks ‚Üí 8 freie Slots
Worker B: 7/10 Tasks ‚Üí 3 freie Slots
Worker C: 0/4 Tasks  ‚Üí 4 freie Slots
‚Üí W√§hlt Worker A (8 freie Slots)
```

### 2. Round Robin
Verteilt gleichm√§√üig √ºber alle verf√ºgbaren Worker im Kreis:
```
Task 1 ‚Üí Worker A
Task 2 ‚Üí Worker B
Task 3 ‚Üí Worker C
Task 4 ‚Üí Worker A (wrap around)
```

### 3. Priority-Based
Bevorzugt Worker mit h√∂herer Priorit√§t:
```
Worker A: Priority 150, 2/10 Tasks
Worker B: Priority 100, 0/10 Tasks
Worker C: Priority 50,  1/4 Tasks
‚Üí W√§hlt Worker A (h√∂chste Priorit√§t mit freien Slots)
```

### 4. Weighted
Ber√ºcksichtigt Performance-History:
```
Score = (Weight √ó 100) + (Freie Slots √ó 10) + (Success Ratio √ó 50) - (Avg Duration / 1000)

Worker A: Weight 1.0, 8 slots frei, 95% success, 5s avg ‚Üí Score: 245
Worker B: Weight 0.8, 3 slots frei, 98% success, 3s avg ‚Üí Score: 210
‚Üí W√§hlt Worker A
```

**Konfiguration:**
```sql
UPDATE config SET config_value = 'least_loaded' WHERE config_key = 'load_balancer_strategy';
-- Optionen: least_loaded, round_robin, priority, weighted
```

---

## Worker Agent (Node.js)

### Installation auf Windows

```powershell
# Voraussetzungen
node --version  # Node.js 20+ erforderlich
npm --version

# Installation
cd C:\Projekte\GE-ECommerce-Testing
mkdir agent
cd agent

# Dependencies
npm init -y
npm install axios

# Konfiguration
$env:COORDINATOR_URL = "https://playwright.your-domain.de"
$env:WORKER_NAME = "laptop-max"
$env:PLAYWRIGHT_PROJECT_PATH = "C:\Projekte\GE-ECommerce-Testing"
$env:POLL_INTERVAL = "60"  # Sekunden

# Agent starten
node worker.js

# Als Service (optional mit PM2)
npm install -g pm2
pm2 start worker.js --name playwright-worker
pm2 save
pm2 startup
```

### Installation auf Linux/Mac

```bash
# Installation
cd ~/projects/GE-ECommerce-Testing
mkdir agent
cd agent

npm init -y
npm install axios

# Konfiguration
export COORDINATOR_URL="https://playwright.your-domain.de"
export WORKER_NAME="desktop-ci"
export PLAYWRIGHT_PROJECT_PATH="/home/user/GE-ECommerce-Testing"
export POLL_INTERVAL="60"

# Agent starten
node worker.js

# Als Service (systemd)
sudo nano /etc/systemd/system/playwright-worker.service
# [Inhalt siehe unten]
sudo systemctl enable playwright-worker
sudo systemctl start playwright-worker
```

### Worker Agent Code (Grundger√ºst)

```javascript
// agent/worker.js
const os = require('os');
const axios = require('axios');
const { exec } = require('child_process');
const util = require('util');
const fs = require('fs').promises;

const execPromise = util.promisify(exec);

// Configuration
const COORDINATOR_URL = process.env.COORDINATOR_URL || 'https://playwright.example.com';
const POLL_INTERVAL = parseInt(process.env.POLL_INTERVAL || '60') * 1000;
const WORKER_NAME = process.env.WORKER_NAME || os.hostname();
const PLAYWRIGHT_PROJECT_PATH = process.env.PLAYWRIGHT_PROJECT_PATH || process.cwd();

let apiKey = null;
let workerId = null;
let isProcessingTask = false;

// Worker capabilities
const capabilities = {
    browsers: ['chromium', 'firefox', 'webkit'],
    max_parallel: 4,
    platform: os.platform(),
    arch: os.arch(),
    cpu_count: os.cpus().length,
    total_memory_gb: Math.round(os.totalmem() / 1024 / 1024 / 1024),
};

async function registerWorker() {
    console.log(`üîå Registering worker: ${WORKER_NAME}`);

    const response = await axios.post(`${COORDINATOR_URL}/api/v1/workers/register`, {
        hostname: WORKER_NAME,
        capabilities: capabilities,
    });

    apiKey = response.data.api_key;
    workerId = response.data.worker_id;

    await fs.writeFile('.worker-api-key', apiKey);
    console.log(`‚úÖ Registered (ID: ${workerId})`);
}

async function pollForTask() {
    if (isProcessingTask) return;

    const response = await axios.get(`${COORDINATOR_URL}/api/v1/tasks/next`, {
        headers: { 'X-API-Key': apiKey },
    });

    if (response.data.task) {
        await executeTask(response.data);
    }
}

async function executeTask(task) {
    isProcessingTask = true;
    console.log(`üöÄ Starting task ${task.task_id}`);

    const config = task.config || {};
    const command = `npx playwright test --shard=${task.shard_index}/${task.shard_total}`;

    try {
        await execPromise(command, { cwd: PLAYWRIGHT_PROJECT_PATH });
        await submitResults(task.task_id, { passed: 10, failed: 0, duration_ms: 5000 });
        console.log(`‚úÖ Task ${task.task_id} completed`);
    } catch (error) {
        await submitResults(task.task_id, { passed: 0, failed: 1, error_log: error.message });
        console.error(`‚ùå Task ${task.task_id} failed`);
    } finally {
        isProcessingTask = false;
    }
}

async function submitResults(taskId, results) {
    await axios.post(
        `${COORDINATOR_URL}/api/v1/tasks/submit-result`,
        { task_id: taskId, ...results },
        { headers: { 'X-API-Key': apiKey } }
    );
}

async function main() {
    console.log('üé≠ Playwright Worker Agent');

    try {
        apiKey = await fs.readFile('.worker-api-key', 'utf8');
    } catch (e) {
        // No existing key
    }

    await registerWorker();

    setInterval(pollForTask, POLL_INTERVAL);
    await pollForTask();
}

main().catch(console.error);
```

---

## Web-Dashboard

### Features

**Dashboard (index.php):**
- Worker-√úbersicht (Status: Idle/Busy/Offline)
- Aktuelle Test-Runs mit Fortschritt
- System-Stats (Gesamt-Tests, Success-Rate)
- Quick-Actions (Test-Run starten, Worker verwalten)

**Worker-Ansicht (workers.php):**
- Detaillierte Worker-Liste mit Capabilities
- Aktuelle Tasks pro Worker
- Performance-Metriken (Avg Duration, Success-Rate)
- Logs & Heartbeat-History

**Test-Runs (runs.php):**
- Liste aller Test-Runs (filtierbar)
- Detailansicht: Task-Status, Progress-Bar
- Ergebnis-Download (HTML-Report, JSON)
- Fehler-Analyse bei Failed Tests

**Analytics (stats.php):**
- Performance-Trends (Chart.js)
- Test-Dauer √ºber Zeit
- Success-Rate Verlauf
- Top 10 langsamste Tests
- Worker-Auslastung

---

## Monitoring & Alerting

### Health Checks

**Worker Health:**
- Heartbeat alle 60 Sekunden
- Offline nach 120 Sekunden ohne Heartbeat
- Automatisches Reassignment von Tasks wenn Worker offline

**Task Monitoring:**
- Task-Timeout nach 1 Stunde (konfigurierbar)
- Automatischer Retry (max 2√ó)
- Heartbeat w√§hrend Task-Ausf√ºhrung

### Alert-Typen

| Alert | Bedingung | Schwere | Benachrichtigung |
|-------|-----------|---------|------------------|
| Test Failure Rate | > 5% in letzten 60 Min | Critical | Slack + Email |
| Worker Offline | Worker seit 5 Min offline | Warning | Slack |
| Slow Tests | P95 > 60s | Warning | Slack |
| Task Timeout | Task l√§uft > 2h | Critical | Email |
| Disk Space Low | < 10% frei | Warning | Slack |

### Benachrichtigungs-Kan√§le

**Slack:**
```sql
UPDATE config
SET config_value = 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
WHERE config_key = 'slack_webhook_url';
```

**Email (SMTP):**
```sql
UPDATE config SET config_value = 'smtp.office365.com' WHERE config_key = 'smtp_server';
UPDATE config SET config_value = '587' WHERE config_key = 'smtp_port';
UPDATE config SET config_value = 'playwright@globetrotter.de' WHERE config_key = 'smtp_from';
```

---

## API-Dokumentation

### Worker Management

```http
POST /api/v1/workers/register
Content-Type: application/json

{
  "hostname": "laptop-max",
  "capabilities": {
    "browsers": ["chromium", "firefox"],
    "max_parallel": 4,
    "platform": "win32"
  }
}

Response 201:
{
  "worker_id": 42,
  "api_key": "abc123...",
  "message": "Worker registered successfully"
}
```

```http
GET /api/v1/tasks/next
X-API-Key: abc123...

Response 200:
{
  "task_id": 123,
  "test_run_id": 45,
  "shard_index": 2,
  "shard_total": 10,
  "config": {
    "browser": "chromium",
    "base_url": "https://www.globetrotter.de"
  }
}
```

```http
POST /api/v1/results/submit
X-API-Key: abc123...
Content-Type: application/json

{
  "task_id": 123,
  "passed": 42,
  "failed": 2,
  "skipped": 1,
  "duration_ms": 125000,
  "report_url": "https://..."
}

Response 200:
{
  "message": "Result submitted successfully",
  "status": "completed"
}
```

### Test Run Management

```http
POST /api/v1/test-runs/create
Content-Type: application/json
Authorization: Bearer admin-token

{
  "name": "Nightly E2E Tests",
  "total_shards": 10,
  "config": {
    "browser": "chromium",
    "base_url": "https://www.globetrotter.de",
    "timeout": 30000
  }
}

Response 201:
{
  "test_run_id": 45,
  "message": "Test run created with 10 shards"
}
```

---

## Vergleich mit Cloud-L√∂sungen

| Kriterium | Custom System | GitHub Actions | k6 + Grafana | Kubernetes |
|-----------|---------------|----------------|--------------|------------|
| **Monatliche Kosten** | ‚Ç¨0 | $30-50 | $60-150 | $450-1.000 |
| **Setup-Zeit** | 48h | 9h | 19h | 48h+ |
| **Max Parallelit√§t** | Unbegrenzt (abh√§ngig von Workern) | 20 Jobs | 500 VUs | 1.000+ Pods |
| **Hardware** | Eigene Rechner + optional Cloud | GitHub Runner | Eigene/Cloud | Cloud |
| **Web-UI** | ‚úÖ Custom | ‚ùå Nur GitHub | ‚úÖ Grafana | ‚úÖ k8s Dashboard |
| **Lokale Rechner** | ‚úÖ Ja | ‚ùå Nein | ‚ö†Ô∏è M√∂glich | ‚ö†Ô∏è M√∂glich |
| **Monitoring** | ‚≠ê‚≠ê‚≠ê Gut | ‚≠ê‚≠ê Basis | ‚≠ê‚≠ê‚≠ê‚≠ê Sehr gut | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Exzellent |
| **Wartung** | Mittel | Niedrig | Mittel | Hoch |
| **Flexibilit√§t** | ‚úÖ Sehr hoch | ‚ùå Limitiert | ‚≠ê‚≠ê‚≠ê Hoch | ‚úÖ Sehr hoch |
| **Vendor Lock-in** | ‚ùå Keiner | GitHub | Gering | Cloud-Anbieter |

---

## Vor- und Nachteile

### Vorteile ‚úÖ

1. **Keine Cloud-Kosten:** Nutzt vorhandenes HostEurope-Hosting (‚Ç¨0 extra/Monat)
2. **Unbegrenzte Skalierung:** Beliebig viele Worker hinzuf√ºgen (Laptops, Desktops, VMs)
3. **Lokale Rechner:** Team-Laptops k√∂nnen w√§hrend Arbeit als Worker dienen
4. **Volle Kontrolle:** Kompletter Zugriff auf Code, Daten, Infrastruktur
5. **Flexible Worker:** Unterschiedliche Hardware-Konfigurationen m√∂glich
6. **Web-Dashboard:** Benutzerfreundliche Oberfl√§che f√ºr Team
7. **Bekannte Technologien:** PHP, MySQL, Node.js - keine neue Lernkurve
8. **Hybrid-Setup:** Mix aus lokalen und Cloud-Workern m√∂glich
9. **Kein Vendor Lock-in:** Vollst√§ndig selbst-gehostet
10. **Custom Extensions:** Einfach erweiterbar mit neuen Features

### Nachteile ‚ùå

1. **Initial Development:** ~48 Stunden Entwicklungszeit
2. **Wartungsaufwand:** 2-4h/Monat f√ºr Updates, Bugfixes
3. **Kein Enterprise-Support:** Keine professionelle Support-Hotline
4. **HostEurope Performance:** Shared Hosting hat Limitierungen
5. **Skalierung:** Bei >50 Workern k√∂nnte MySQL zur Bottleneck werden
6. **Monitoring:** Kein Prometheus/Grafana-Level Observability
7. **Security:** API-Key-Verwaltung muss sicher implementiert werden
8. **Backup:** Manuelles Backup-System erforderlich
9. **High Availability:** Kein automatisches Failover bei HostEurope-Ausfall
10. **Worker-Verwaltung:** Manuelle Installation auf allen Rechnern

---

## Sicherheits-√úberlegungen

### API-Sicherheit

**API-Key-Generation:**
```php
$api_key = bin2hex(random_bytes(32)); // 64 Zeichen SHA256
```

**Best Practices:**
- API-Keys in `.env` Dateien speichern (nie in Git)
- HTTPS obligatorisch (Let's Encrypt SSL)
- Rate-Limiting auf API-Endpunkten
- Input-Validation & SQL-Injection Prevention (Prepared Statements)
- CORS-Header richtig konfigurieren

### Worker-Sicherheit

**Isolation:**
- Worker l√§uft mit eigenen Berechtigungen
- Playwright-Tests in Sandbox ausf√ºhren
- Keine Secrets im Test-Code (√ºber ENV-Vars)

**Network:**
- Worker ‚Üí Coordinator: HTTPS
- Firewall: Nur ausgehende Verbindungen erlauben

---

## Deployment-Checkliste

### HostEurope Setup

- [ ] MySQL-Datenbank erstellen (phpMyAdmin)
- [ ] `schema-detailed.sql` importieren
- [ ] PHP-Dateien via FTP hochladen
- [ ] `.htaccess` f√ºr Clean URLs konfigurieren
- [ ] SSL-Zertifikat aktivieren (Let's Encrypt)
- [ ] Cron-Job f√ºr Scheduler einrichten
- [ ] Backup-Strategie definieren

### Worker Installation

- [ ] Node.js 20+ installieren auf allen Rechnern
- [ ] `agent/` Ordner kopieren
- [ ] `npm install` ausf√ºhren
- [ ] ENV-Variablen setzen (Coordinator-URL, etc.)
- [ ] Worker-Agent starten
- [ ] Als Service konfigurieren (pm2/systemd)
- [ ] Im Dashboard verifizieren (Worker sollte als "idle" erscheinen)

### Testing

- [ ] Test-Run manuell √ºber Dashboard starten
- [ ] Verifizieren dass Tasks verteilt werden
- [ ] Ergebnisse pr√ºfen
- [ ] Logs kontrollieren
- [ ] Alert-System testen (Slack/Email)
- [ ] Load-Test mit vielen parallelen Tasks

---

## Erweiterungsm√∂glichkeiten

### Phase 2 Features (sp√§ter)

1. **Docker-Support:** Worker als Docker-Container
2. **Grafana-Integration:** Performance-Dashboards
3. **GitHub Integration:** Auto-Trigger bei Push
4. **Flaky Test Detection:** Automatische Erkennung instabiler Tests
5. **Test-Priorisierung:** H√§ufig fehlende Tests zuerst ausf√ºhren
6. **Visual Regression:** Screenshot-Vergleich
7. **Mobile Testing:** Ger√§te-Farm Integration
8. **API-Testing:** REST/GraphQL Tests
9. **Performance Budgets:** Automatische Warnungen bei Slow-Down
10. **Multi-Tenancy:** Mehrere Teams/Projekte

---

## Kostenvergleich (12 Monate)

| L√∂sung | Setup | Monatlich | Jahr 1 | Jahr 2 |
|--------|-------|-----------|--------|--------|
| **Custom System** | 48h √ó ‚Ç¨80 = ‚Ç¨3.840 | ‚Ç¨0 | ‚Ç¨3.840 | ‚Ç¨0 |
| **GitHub Actions** | 9h √ó ‚Ç¨80 = ‚Ç¨720 | $50 | ‚Ç¨1.320 | ‚Ç¨600 |
| **k6 + Grafana** | 19h √ó ‚Ç¨80 = ‚Ç¨1.520 | $100 | ‚Ç¨2.720 | ‚Ç¨1.200 |
| **Kubernetes** | 48h √ó ‚Ç¨80 = ‚Ç¨3.840 | $500 | ‚Ç¨9.840 | ‚Ç¨6.000 |

**Break-Even:**
- vs GitHub Actions: Nach 3 Jahren
- vs k6: Nach 2 Jahren
- vs Kubernetes: Nach 1 Jahr

**Bei hoher Nutzung (t√§glich 10 Test-Runs):**
- GitHub Actions: $200/Monat ‚Üí Break-Even nach 1,6 Jahren
- Custom System amortisiert sich schneller bei intensiver Nutzung

---

## Empfehlung & N√§chste Schritte

### Empfehlung: JA, umsetzen! ‚úÖ

Das Custom Test Orchestration System ist f√ºr euren Use-Case **optimal**, weil:

1. ‚úÖ Vorhandenes HostEurope-Hosting nutzen (keine extra Kosten)
2. ‚úÖ Team-Rechner als Worker nutzen (keine neue Hardware)
3. ‚úÖ Skalierbar auf 100+ parallele Tests
4. ‚úÖ Volle Kontrolle & Flexibilit√§t
5. ‚úÖ Bekannte Technologien (PHP, Node.js)
6. ‚úÖ Keine laufenden Cloud-Kosten

### Implementierungs-Plan

**Sprint 1 (Woche 1-2): Foundation**
- Datenbank-Schema implementieren
- API-Grundger√ºst aufsetzen
- Load-Balancer implementieren

**Sprint 2 (Woche 3-4): Worker Agent**
- Node.js Agent entwickeln
- Playwright-Integration
- Testing auf 2-3 Rechnern

**Sprint 3 (Woche 5-6): Web-Dashboard**
- Dashboard-UI entwickeln
- Worker-Verwaltung
- Test-Run-Ansicht

**Sprint 4 (Woche 7): Polish & Deploy**
- Bugfixes
- Deployment auf HostEurope
- Team-Schulung
- Dokumentation

### Sofort starten mit

1. **Proof of Concept (8h):**
   - Minimales Schema (workers, tasks, test_runs)
   - Einfacher Worker-Agent
   - Basic API (register, get-task, submit-result)
   - ‚Üí Zeigt Machbarkeit

2. **Dann entscheiden:** PoC erfolgreich? ‚Üí Full Implementation

---

## Fragen & Antworten

**Q: Kann ich auch Cloud-Worker verwenden?**
A: Ja! AWS EC2 Spot Instances, Azure VMs, etc. k√∂nnen als Worker dienen. Agent einfach dort installieren.

**Q: Was passiert wenn HostEurope down ist?**
A: Worker k√∂nnen nicht neu starten, laufende Tests werden zu Ende gef√ºhrt. Danach warten Worker bis Coordinator wieder online ist.

**Q: Wie viele Worker sind realistisch?**
A: Bei normalem Setup (MySQL auf Shared Hosting): ~50 Worker. Mit dediziertem Server: 500+.

**Q: K√∂nnen Worker in verschiedenen Netzwerken sein?**
A: Ja, solange sie HTTPS-Zugriff auf HostEurope haben. Auch √ºber VPN m√∂glich.

**Q: Wie lange dauert ein typischer Test-Run?**
A: Mit 10 Workern @ 10 parallel = 100 Tests gleichzeitig. 1.000 Tests @ 30s/Test = 300s = **5 Minuten**.

---

## Kontakt & Support

**Projekt-Owner:** [Name]
**Tech-Lead:** [Name]
**Repository:** `GE-ECommerce-Testing`
**Dokumentation:** `/docs/remote-setup-feature.md`

---

**Status:** ‚úÖ Ready for Implementation
**Letzte Aktualisierung:** 2026-02-01
